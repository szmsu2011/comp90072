% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames,x11names}{xcolor}
%
\documentclass[
]{article}
\usepackage{amsmath,amssymb}
\usepackage{lmodern}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\usepackage[margin=1in]{geometry}
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
\newlength{\cslhangindent}
\setlength{\cslhangindent}{1.5em}
\newlength{\csllabelwidth}
\setlength{\csllabelwidth}{3em}
\newlength{\cslentryspacingunit} % times entry-spacing
\setlength{\cslentryspacingunit}{\parskip}
\newenvironment{CSLReferences}[2] % #1 hanging-ident, #2 entry spacing
 {% don't indent paragraphs
  \setlength{\parindent}{0pt}
  % turn on hanging indent if param 1 is 1
  \ifodd #1
  \let\oldpar\par
  \def\par{\hangindent=\cslhangindent\oldpar}
  \fi
  % set entry spacing
  \setlength{\parskip}{#2\cslentryspacingunit}
 }%
 {}
\usepackage{calc}
\newcommand{\CSLBlock}[1]{#1\hfill\break}
\newcommand{\CSLLeftMargin}[1]{\parbox[t]{\csllabelwidth}{#1}}
\newcommand{\CSLRightInline}[1]{\parbox[t]{\linewidth - \csllabelwidth}{#1}\break}
\newcommand{\CSLIndent}[1]{\hspace{\cslhangindent}#1}
\usepackage{algorithm}
\usepackage{algorithmic}
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same} % disable monospaced font for URLs
\hypersetup{
  pdftitle={Respiratory Rate Determination by ECG Signals},
  pdfauthor={Stephen Su, 844503, COMP90072},
  colorlinks=true,
  linkcolor={Maroon},
  filecolor={Maroon},
  citecolor={Blue},
  urlcolor={blue},
  pdfcreator={LaTeX via pandoc}}

\title{Respiratory Rate Determination by ECG Signals}
\author{Stephen Su, 844503, COMP90072}
\date{}

\begin{document}
\maketitle

\hypertarget{introduction}{%
\section{Introduction}\label{introduction}}

\hypertarget{background}{%
\subsection{Background}\label{background}}

Pneumonia is the deadliest infectious disease to children under the age
of 5, responsible for 740,180 deaths under 5 as of 2019 (World Health
Organisation, 2022). The worsening symptoms of pneumonia can rapidly
become life-threatening for young children if not treated on time.
Nevertheless, the early stage of pneumonia with young children is often
confused with other less serious respiratory disease with similar
symptoms. On the other hand, a medical institution cannot provide
comprehensive monitoring to all its patients for all potential symptoms
of pneumonia due to limitation of resources. Thus it is of interest to
develop light-weight, non-evasive methods for detecting the most common
symptoms of pneumonia, as an early warning to serve as an indication of
a need for further medical interventions.

In a research outlined in Shamo'on et al. (2004), tachypnoea (average
respiratory rate \textgreater{} 50 per minute) is one of the critical
indicators of pneumonia in young children. However, the high volatility
of breath rate in children poses a major challenge for manual counting
that is both time-consuming and prone to error. In contrary, automated
respiratory monitoring often involves machine-measurement of
chest/abdomen movement or nasal airflow that are resource-costly and
possibly invasive such that the discomfort from wearing the equipment
might adversely affect its accuracy.

A potential solution to the problem above arises from the phenomenon of
\emph{respiratory sinus arrhythmia}, such that the instantaneous heart
rates increase with inspiration and decrease during expiration (Larsen
et al., 2010), by monitoring the periodicity of variation in the heart
rate, it may be possible to determine one's respiratory rate with a
simple, non-evasive method, such as by a pulse oximeter that is
resource-friendly. As such, this project attempts to develop an
efficient \emph{predictive} algorithm to accurately and precisely
determine respiratory rate from heart rate, as well as briefly discuss
its limitations and direction for future works.

\hypertarget{the-data}{%
\subsection{The data}\label{the-data}}

The \emph{apnea-ECG database} (Penzel et al., 2000) on \emph{PhysioNet}
(Goldberger et al., 2000) provides sufficiently large data sets of
approximately eight hours long records of electrocardiogram and
respiratory signals for eight subjects in a study for \emph{sleep
apnea}. The eight records consist of 100Hz signal from the
electrocardiogram (ECG), respiratory effort from chest/abdomen
movements, nasal airflow, and blood O\(_2\) saturation over time.

A major concern of using such data is the misalignment of objective for
the researches. Study for apnea typically involves subjects with airway
obstruction, a factor that must be considered for prior to building our
model. Under the presumption that, subjects in our data might sometimes
stop breathing, the response variable of interest should be robust from
the presence of apnea. Therefore, the model will focus on exploring the
algorithm for determining the respiratory rate from the ECG signal as a
predictor for the respiratory rate implied by chest movements, assuming
that for living humans, respiratory efforts are always present.

This study will divide records from the eight subjects into two sets:

\begin{itemize}
\tightlist
\item
  Subjects a01, a02, a03, a04 and b01 form the \emph{training set}.
\item
  Subjects c01, c02 and c03 form the \emph{test set} for evaluation.
\end{itemize}

\newpage

\hypertarget{methodologies-and-implementation}{%
\section{Methodologies and
implementation}\label{methodologies-and-implementation}}

\hypertarget{data-wrangling}{%
\subsection{Data wrangling}\label{data-wrangling}}

\hypertarget{processing-ecg-signals}{%
\subsubsection{Processing ECG signals}\label{processing-ecg-signals}}

The ECG signal does not provide the heart rate directly. Instead, it is
a time series of varying electric potential that controls the rhythm of
the contraction and relaxation of the heart muscle, with a magnitude of
approximately 0.5mV in absolute value. Such a signal is often masked by
unwanted noise, such as electric signals from pectoral muscle movement,
creating a challenge in computing heart rate from the ECG signal.

\begin{figure}

{\centering \includegraphics{report_files/figure-latex/ecg-noise-1} 

}

\caption{Top: sudden spike in noise; bottom: frequency spectrum of the ECG signal}\label{fig:ecg-noise}
\end{figure}

Cardio-activities are reflected in the ECG signal as time series of QRS
complex as counts for complete heart beats (Goldberger et al., 2017),
where the instantaneous heart rates are determined by the interval of
consecutive R-peaks, characterised by a positive crest in electric
potential with a frequency of approximately 10--20Hz, and are
distinguishable from P and T peaks with frequencies mostly below 5Hz.

Apart from muscle-induced electric noise, another challenge arises from
abnormally peaked P and T waves from a variety of heart conditions (for
example, abnormally peaked T waves observed on subject
\protect\hyperlink{visual}{a02}). Upon de-noising the ECG signal, it is
also needed to suppress the peaks for P and T waves. Otherwise, they
become less distinguishable from the R peaks amplitude-wise and might be
mistakenly flagged as R peaks.

\begin{figure}

{\centering \includegraphics{report_files/figure-latex/qrs-1} 

}

\caption{An example QRS complex from the ECG signal for one complete heart beat}\label{fig:qrs}
\end{figure}

Intuitively, the simplest method for reducing the noise and suppressing
P and T peaks is to filter out their typical frequencies. With observed
frequencies of noise from the frequency spectrum mostly above 20Hz, and
the characteristic frequencies of P and T waves being below 5Hz, we may
utilise the Discrete Fourier Transform (DFT) (Cooley \& Tukey, 1965), to
create a band-pass filter, retaining only 5--20Hz signals from the ECG
data. The DFT transformed signal compromises the Nyquist frequency bins
(with its range being half of sampling frequency) (Nyquist, 1928)
corresponding to each of the harmonic. The band-pass filtered signal is
then obtained by applying the (normalised) inverse Discrete Fourier
Transform to the DFT transformed signal, with zeroed frequency bins for
0-5 and 20-50Hz. For computational efficiency, the Discrete Fourier
Transform is implemented by R (R Core Team, 2023) with the Fast Fourier
Transform (FFT) algorithm (Singleton, 1979) using the already available
\texttt{fft()} function (Becker et al., 1988).

It is worth noting that, the DFT approach to band-pass filtering as per
outlined above has not accounted for the modulation effect from Fourier
Transform, and will likely cause phase shifts in the de-noised signals.
Nevertheless, upon thorough inspection, the observed phase error in the
filtered output are mostly within 10--20ms, and easily correctable with
local peak-matching, which is discussed in the following paragraphs.

\emph{Note: most ``for loops'' in the pseudocode algorithms in this
report are implicitly implemented by vectorisation.}

\begin{algorithm}
\caption{5--20Hz band-pass filter with Discrete Fourier Transform}
\begin{algorithmic}[1]
\STATE Take $\mathbf{x} \in \mathbb{R}^n$ as the 100-Hz input
\STATE Obtain $\mathbf{y}$ by Discrete Fourier Transform on $\mathbf{x}$:
\FOR{$t = 1, ..., n$}
\STATE $y_t \leftarrow \sum_{k = 1}^n{x_k}\exp(-2\pi i(k - 1)(t - 1) / n)$
\ENDFOR
\STATE Zero corresponding (Nyquist) frequency bins for 0-5, 20-50Hz:
\FOR{$t = 1, ..., n \land (t \in (0.2n, 0.8n) \lor t > 0.95n \lor t < 0.05n)$}
\STATE $y_t \leftarrow 0 + 0i$
\ENDFOR
\STATE Obtain $\mathbf{z}$ by normalised inverse Discrete Fourier Transform on $\mathbf{y}$:
\FOR{$t = 1, ..., n$}
\STATE $z_t \leftarrow \sum_{k = 1}^n{y_k}\exp(2\pi i(k - 1)(t - 1) / n) / n$
\ENDFOR
\RETURN $\text{Re}(\mathbf{z}) \in \mathbb{R}^n$ as the 100-Hz output
\end{algorithmic}
\end{algorithm}

With the de-noised ECG signal, a special algorithm for timestamping the
R peaks is developed based on logical check for local maxima and double
thresholding. For the amplitudes of P and T peaks are suppressed in the
filtered signal, the local maxima above certain threshold in the series
are the R peaks. For a series of discrete-time signal, the local maxima
are indicated by whenever the signs of the first difference change from
\emph{positive} to \emph{negative}. Also, as the R peaks are more than
triple the amplitude of the DFT suppressed P and T peaks, all local
maxima with an amplitude of at least half (in prudence) the amplitude of
previous peak are indicated as the R peaks. Upon implementation, the
threshold is set at half of the rolling maxima for the last 101 ticks
(1.01s). For extra caution to unlikely events when there is no heart
beat in the past 1.01 seconds, a second threshold, the 95\% empirical
quantile of amplitude of the signal, is imposed. All time-points in the
filtered ECG signal that are deemed as local maxima also with amplitude
above the two thresholds are stamped as R peaks. The algorithm is fast
even for long ECG signal.

There are, however, issues that cannot be dealt with via aforementioned
algorithms. While the algorithms are robust against moderate noise with
filtering, they will unlikely function in the presence of extreme noise
with amplitude exceeding the original signal. Under such extreme noise,
which is rarely seen, the stamped R peaks would manifest small clusters
of abnormally short R-R intervals, typically below 300ms. Therefore, an
additional check is implemented to identify and remove all the abnormal
timestamps. Another issue with the algorithm is the phase shift induced
by Fourier Transform. Without taking care for the modulation harmonics,
the timestamps obtained from the filtered signal are \(\pm10\)--20ms
away from the true observed R peaks in the original signal. Fortunately,
the phase errors are small and can be easily corrected by searching for
the existence of another peak around the neighbours in the original
signal.

\begin{algorithm}
\caption{R peak timestamping with phase correction}
\begin{algorithmic}[1]
\STATE Take the original $\mathbf{x} \in \mathbb{R}^n$ and the filtered $\mathbf{z} \in \mathbb{R}^n$ as the 100-Hz inputs
\STATE Set moving threshold $\mathbf{b}$ as half of rolling maxima:
\STATE $(b_t | t = 1, ..., 100) \leftarrow (+\infty)_{\times 100}$ (rolling maxima is undefined for the first second, pad using $+\infty$)
\FOR{$t = 101, ..., n$}
\STATE $b_t \leftarrow \frac{1}{2}\max\{z_{t - 100}, ..., z_t\}$
\ENDFOR
\STATE Create thresholding Boolean $\boldsymbol{\iota^{(1)}}$:
\FOR{$t = 1, ..., n$}
\STATE $\iota^{(1)}_t \leftarrow I(z_t > \max\{b_t, F^{-1}_{Z}(0.95)\})$
\ENDFOR
\STATE Create local maxima Boolean $\boldsymbol{\iota^{(2)}}$:
\FOR{$t = 1, n$}
\STATE $\iota^{(2)}_t \leftarrow 0$ (local maxima are undefined for the boundaries)
\ENDFOR
\FOR{$t = 2, ..., n - 1$}
\STATE $\iota^{(2)}_t \leftarrow I[I(z_{t + 1} - z_t > 0) - I(z_t - z_{t - 1} > 0) = -1]$
\ENDFOR
\STATE Preliminary timestamps for R peak $\mathbf{p} \leftarrow (t = 1, ..., n | \iota^{(1)}_t \land \iota^{(2)}_t = 1 \text{ is True})$
\STATE Remove abnormal timestamps in $\mathbf{p}$ with R-R intervals of < 300ms
\STATE Correct phase-shifts caused by discrete Fourier Transform:
\FOR{$t \in \{\mathbf{p}\}$}
\STATE $p | p = t \leftarrow {\arg\max}_{i = t - 4, ..., t, ..., t + 4} x_i$
\ENDFOR
\RETURN $\mathbf{p}$ the timestamps of the R peak
\end{algorithmic}
\end{algorithm}

\newpage

\hypertarget{heart-rate-derivation-from-ecg-signals}{%
\subsubsection{Heart rate derivation from ECG
signals}\label{heart-rate-derivation-from-ecg-signals}}

Once all the time points of R peaks are identified, we have cleared all
obstructions to determining the heart rate. At any point in time within
the series of ECG signal, the instantaneous heart rate is determined by
interval between the subsequent and consequent R peaks. While one might
explicitly loop over all the \(5 \times 3\) million data points in ECG
to obtain the series of intervals between R peaks, the process can be
more efficient via vectorisation. It can be shown, with an example, that
the derived series of R-R interval as a function of series of timestamps
of the R peaks, is equivalent to repeating the differenced timestamps
each for numbers of times equalled to the differenced timestamps
themselves.

\emph{For example, the R peaks are on the 3rd, 7th, 10th and 12th time
ticks (for illustration purpose only), then the series of R-R interval
can be computed by the following R (R Core Team, 2023) code:}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{r\_peak }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{3}\NormalTok{, }\DecValTok{7}\NormalTok{, }\DecValTok{10}\NormalTok{, }\DecValTok{12}\NormalTok{)}
\NormalTok{r\_peak}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
#> [1]  3  7 10 12
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{rr\_interval }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\FunctionTok{rep}\NormalTok{(}\ConstantTok{NA}\NormalTok{, r\_peak[}\DecValTok{1}\NormalTok{]), }\FunctionTok{rep}\NormalTok{(}\FunctionTok{diff}\NormalTok{(r\_peak), }\FunctionTok{diff}\NormalTok{(r\_peak)))}
\NormalTok{rr\_interval}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
#>  [1] NA NA NA  4  4  4  4  3  3  3  2  2
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{length}\NormalTok{(rr\_interval)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
#> [1] 12
\end{verbatim}

The series of instantaneous heart rate per minute is then obtainable by
60 \(\times\) frequency \(/\) R-R intervals.

\begin{algorithm}
\caption{Deriving instantaneous heart rates from R peak timestamps}
\begin{algorithmic}[1]
\STATE Take $\mathbf{p}$ the timestamps of the R peak as the input, and $\nu$ as an argument for the frequency unit of $\mathbf{p}$
\STATE $m \leftarrow \dim(\mathbf{p})$ dimension of $\mathbf{p}$
\STATE Compute the R-R intervals $\mathbf{d}$:
\STATE $(d_t | t = 1, ..., p_1) \leftarrow (\text{NA})_{\times p_1}$ (heart rate is undefined before the first R peak)
\STATE $(d_t | t = p_1 + 1, ..., p_{m}) \leftarrow ((p_2 - p_1)_{\times (p_2 - p_1)}, (p_3 - p_2)_{\times (p_3 - p_2)}, ..., (p_{m} - p_{m - 1})_{\times (p_{m} - p_{m - 1})})^\top$
\STATE Convert R-R intervals into heart rates per minute $\mathbf{h}$:
\STATE $\mathbf{h} \leftarrow 60 \cdot \nu / \mathbf{d}$
\RETURN $\mathbf{h}$ the heart rates per minute at frequency $\nu$
\end{algorithmic}
\end{algorithm}

The output series of instantaneous heart rate is a signal at 100Hz with
stepped (quantised) values, as the resolution of the derived heart rate
is limited by the sampling frequency of the ECG signal (see next page).

\hypertarget{visual}{%
\subsubsection{Visualising ECG signal processing}\label{visual}}

\begin{center}\includegraphics{report_files/figure-latex/ecg-process-1} \end{center}

\hypertarget{modelling-rate-of-breathing-by-heart-rate}{%
\subsection{Modelling rate of breathing by heart
rate}\label{modelling-rate-of-breathing-by-heart-rate}}

As per phenomenon of \emph{respiratory sinus arrhythmia} described in
Larsen et al.~(2010), we expect to observe a periodic variation in heart
rates with chest movements while breathing. Therefore, the final
objective is to develop an algorithm to accurately ``count'' the number
of respiration from both heart rate variation and chest movements, and
hence construct a model to predict the rate of respiration using heart
rate alone.

\hypertarget{the-smoothing-spline-crossing-algorithm}{%
\subsubsection{The smoothing spline crossing
algorithm}\label{the-smoothing-spline-crossing-algorithm}}

An algorithm, which I name the smoothing spline crossing algorithm, was
inspired by the idea of zero crossing (Giannakopoulos \& Pikrakis,
2014), often used in audio processing for estimating the number of wave
oscillations from the number of sign changes (when the signal has
crossed the zero axis):

\begin{align*}
  \text{Z}(\mathbf{a}) \approx \frac{1}{2} \sum_{t = 2}^{\dim(\mathbf{a})} |\text{sgn}(a_t) - \text{sgn}(a_{t - 1})|
\end{align*}

For series with a nonzero mean, a generalisation to zero crossing is to
count the oscillations by mean crossing:

\begin{align*}
  \text{Z}(\mathbf{a}) \approx \frac{1}{2} \sum_{t = 2}^{\dim(\mathbf{a})} |\text{sgn}(a_t - \bar{a}) - \text{sgn}(a_{t - 1} - \bar{a})|
\end{align*}

Nonetheless, the mean crossing estimate only works well if, and only if
each oscillation almost always crosses the sample mean, e.g., an almost
perfect sinusoidal wave. Yet the series of instantaneous heart rate and
chest movement signals manifested oscillations with irregular cycles of
nonstationary mean, such that a naive application of mean crossing will
inevitably give a highly biased oscillation count. We thus need to find
an alternative to sample mean for crossing for a better count of number
of cycles for a nonstationary oscillation.

The smoothing spline (Green \& Silverman, 1994; Hastie \& Tibshirani,
1990) is a bivariate smoothing method based on regularised regression to
a natural cubic spline basis, penalised by the integrated squared second
derivative (which represents the roughness) of the smoothed curve,
depictable as a function:

\begin{align}
  \mathbf{\hat{a}} = \hat{f}(\mathbf{t} ; \lambda) = \mathop{\arg\min}\limits_{f(\mathbf{t})} \Bigr\{\sum_{t = 1}^{\dim(\mathbf{a})}(a_t - f(t))^2 + \lambda\int_t f''(s)^2ds\Bigr\} \text{ given any } \lambda > 0
\end{align}

Where \(\lambda\) is the regularisation parameter controlling the
penalty to the roughness of the fitted values, which effectively
determines how smooth the fitted curve becomes. With \emph{properly}
selected \(\lambda\), we are able to draw a better boundary for
crossing, to give a better count for the oscillations, than the sample
mean of the heart rates and chest movements. The proposed smoothing
spline crossing method is given by:

\begin{align*}
  \text{S}(\mathbf{a} ; \lambda) &\approx \frac{1}{2} \sum_{t = 2}^{\dim(\mathbf{a})} |\text{sgn}(a_t - \hat{a}_t) - \text{sgn}(a_{t - 1} - \hat{a}_{t - 1})| \\
  &= \frac{1}{2} \sum_{t = 2}^{\dim(\mathbf{a})} |\text{sgn}(a_t - \hat{f}(t ; \lambda)) - \text{sgn}(a_{t - 1} - \hat{f}(t - 1 ; \lambda))|
\end{align*}

The smoothing spline fitting for heart rates and chest movements signal
is implemented using R (R Core Team, 2023) function
\texttt{smooth.spline()} (Chambers \& Hastie, 1992). It uses the
\emph{B-spline}-equivalent to the natural cubic spline, a linear
transformation of the spline basis to an orthonormal basis such that it
gives the same smoothing curve, but numerically stabler in computation.
The process of minimising the loss function in (1), numerically solving
its first-order condition, is included in Algorithm 4 in matrix form.

It is noteworthy that the computational burden of the
\texttt{smooth.spline()} function (Chambers \& Hastie, 1992) arises from
matrix computation for numerically solving the inverse of cross product
for the \emph{B-spline} basis, and such operation costs
\(O(\dim(\mathbf{a})^3)\) computation time. However, with our
minutely-segmented approach (see the \protect\hyperlink{mod-train}{next
section} and Algorithm 5), number of data points in each of the segment
is constant; and since the number of segments is proportional to
\(\dim(\mathbf{a})\), it reduces the computation time to
\(O(\dim(\mathbf{a}))\). Yet with over 15 million data points in the
training set, the fitting process for the smoothing spline would still
be unnecessarily slow, for considering the rate of breathing of an
average child, a sampling frequency of 100Hz is redundantly high, for
the purpose of capturing respiratory information. For this report, heart
rates and chest movements signal is down-sampled to 1Hz immediately
after filtering and prior to fitting. Note that, the selection of 1Hz is
based on trial and not theoretically justified, but can be easily
changed to another frequency if really necessary. Another practical
reason for using 1Hz is that our subjects are adults. Further researches
may study the adaptive selection of sampling frequencies, to best
balance accuracy and efficiency.

\begin{algorithm}
\caption{Smoothing spline crossing for counting cycles of nonstationary pseudosinusoidal oscillations, for varying heart rates/chest movements}
\begin{algorithmic}[1]
\STATE Take a time series vector $\mathbf{a}$ at any frequency, and the optional argument $\lambda$ the regularisation parameter
\STATE $\mathbf{t} \leftarrow (1, ..., \dim(\mathbf{a}))^\top$ as the indexing vector
\STATE Construct B-spline bases $\mathbf{B}$ derived from natural cubic spline bases about all possible knots of $\mathbf{t}$
\STATE Penalty matrix $\boldsymbol{\Omega} \leftarrow \{\omega_{jk} = \int_t {B_j^{''}(s)B_k^{''}(s)}ds | B_j(t_i) = (\mathbf{B})_{ij}\}$
\IF{argument $\lambda$ is missing}
\STATE $\lambda \leftarrow {\arg\min}_{\lambda > 0} (1 - \text{tr}(\mathbf{B}(\mathbf{B}^\top\mathbf{B} + \lambda\boldsymbol{\Omega})^{-1}\mathbf{B}^\top) / \dim(\mathbf{a}))^{-2}||(\mathbf{I} - \mathbf{B}(\mathbf{B}^\top\mathbf{B} + \lambda\boldsymbol{\Omega})^{-1}\mathbf{B}^\top)\mathbf{a}||^2$
\ENDIF
\STATE $\mathbf{\hat{a}} \leftarrow \mathbf{B}(\mathbf{B}^\top\mathbf{B} + \lambda\boldsymbol{\Omega})^{-1}\mathbf{B}^\top\mathbf{a}$
\STATE Count the number of times the curves $(\mathbf{t}, \mathbf{a})$ and $(\mathbf{t}, \mathbf{\hat{a}})$ cross (equivalent to zero-crossing for $(\mathbf{t}, \mathbf{a} - \mathbf{\hat{a}})$)
\RETURN half of the count obtained above as the approximated cycles
\end{algorithmic}
\end{algorithm}

\begin{figure}

{\centering \includegraphics{report_files/figure-latex/sszc-1} 

}

\caption{Time series of chest movement (top) and heart rates (bottom) at 1Hz for 1 minute. Blue: naive mean-crossing gives a count of 11.5 and 6 breaths; red: smoothing spline crossing gives a count of 19.5 and 16.5 breaths. We can clearly see that smoothing spline performs much better in counting breaths.}\label{fig:sszc}
\end{figure}

\hypertarget{mod-train}{%
\subsubsection{Model training}\label{mod-train}}

(Incomplete)

\begin{algorithm}
\caption{Deriving breath rate from heart rate based on chest movements}
\begin{algorithmic}[1]
\STATE Take $\mathbf{h}$ the heart rates per minute and $\mathbf{c}$ the chest movements signal (either at 100Hz or down-sampled) where both time series have aligned indices and identical frequency; and optional argument $\lambda_\text{opt}$ (only in model evaluation with test data)
\STATE For both $\mathbf{h}$ and $\mathbf{c}$, remove elements of index where $c_t = \text{NA}$
\FOR{each record of all the subjects}
\STATE Partition each of $\mathbf{h}$ and $\mathbf{c}$ into segments of 60-second data
\ENDFOR
\STATE Drop the remainder (last segment), which is less than 60 seconds
\IF{$\mathbf{h}$ and $\mathbf{c}$ for more than one subject is input}
\STATE Bind $\mathbf{h}$ and $\mathbf{c}$ of all subjects together
\ENDIF
\FOR{each 60-second segment of $\mathbf{c}$}
\STATE Pass each minute of $\mathbf{c}$ into Algorithm 4 (the smoothing spline crossing, without specifying $\lambda$) to compute the true rate of breath based on chest movements, and output $\rightarrow \mathbf{r}$
\ENDFOR
\IF{argument $\lambda_\text{opt}$ is missing}
\STATE $\lambda_\text{opt} \leftarrow {\arg\min}_{\lambda > 0} ||\mathbf{r} - \hat{f}(\mathbf{h}; \lambda)||^2$ where $\hat{f}$ is the Algorithm 4: applied on each minute of $\mathbf{h}$ given $\lambda$
\ENDIF
\STATE $\hat{\lambda}_\text{opt} \leftarrow \lambda_\text{opt}$: if its value is obtained by Step 14 $\hat{\lambda}_\text{opt}$ is the estimate of $\lambda_\text{opt}$ derived from the training data; otherwise, if $\lambda_\text{opt}$ is passed as an argument, then the purpose of this algorithm is model testing
\FOR{each 60-second segment of $\mathbf{h}$}
\STATE Pass each minute of $\mathbf{h}$ into Algorithm 4 (with argument of $\lambda = \hat{\lambda}_\text{opt}$) to compute the derived rate of breath from heart rate, and output $\rightarrow \mathbf{\hat{r}}$ which is the model's estimate of $\mathbf{r}$: the chest rate of breath
\ENDFOR
\RETURN data matrix $(\mathbf{r}, \mathbf{\hat{r}})$, a bi-variate time series (minutely), $\mathbf{r} :=$ "count of breaths by chest movements (observations)" and $\mathbf{\hat{r}} :=$ "number of breaths derived by cardio-activities of that minute (fitted values)", and most importantly $\hat{\lambda}_\text{opt}$ the trained parameter for our final model!
\end{algorithmic}
\end{algorithm}

\newpage

\hypertarget{model-diagnostics}{%
\subsection{Model diagnostics}\label{model-diagnostics}}

The trained model implied that one's heart rate is useful for inferring
the rate of breath, and the results are statistically significant based
on the regularisation result. If there is null relationship between the
heart rate and rate of breath, the trained model should have returned a
\emph{least-complex fit} such that \(L_2\) loss function
(cross-validated MSE) is minimised at large \(\lambda\) and is
monotonically decreasing. Hence, the obvious inverted bell curve
exhibited by the regularised \(L_2\) loss with one minimum gives
evidence against a \emph{null-model fit}.

\begin{figure}

{\centering \includegraphics{report_files/figure-latex/resid-check-1} 

}

\caption{Left: the existence of residual trend, indicates a nonzero bias; right: visual representation of the bias-variance tradeoff via regularisation, the result indicates that the model is more useful than null model.}\label{fig:resid-check}
\end{figure}

Notwithstanding the model being shown useful for predicting the rate of
breath using the heart rate, it gives biased estimates for predictions.
For all \emph{best linear unbiased estimators} (BLUE), such as
\emph{least square estimators}, residuals:
\(\mathbf{r} - \mathbf{\hat{r}}\), are orthogonal (therefore,
independent) to the fitted values: \(\mathbf{\hat{r}}\). But, the final
model gives
\(\hat{\text{Corr}}(\mathbf{\hat{r}}, \mathbf{r} - \mathbf{\hat{r}}) = -0.3976376\)
implying
\(\text{Bias}(\mathbf{\hat{r}}) = \mathbb{E}(\mathbf{\hat{r}}) - \mathbf{r} \neq \mathbf{0}\).
Such bias is introduced intentionally due to regularisation to reduce
variance of the estimator \(\mathbf{\hat{r}}\). More comparatively:

\begin{align*}
  \text{BLUE }&\text{minimises Var} (\mathbf{\hat{r}}) \text{ subject to Bias} (\mathbf{\hat{r}}) = \mathbf{0} \\
  \text{Regularised estimator }&\text{minimises MSE} (\mathbf{\hat{r}}) = \mathbb{E}((\mathbf{r} - \mathbf{\hat{r}})^2) = \text{Var}(\mathbf{\hat{r}}) + \text{Bias}(\mathbf{\hat{r}})^2
\end{align*}

While BLUE has constraints
\(\text{Bias}(\mathbf{\hat{r}}) = \mathbf{0}\) (always aims for
maximising accuracy first), it unwantedly inflates the variance of the
estimator. Whereas regularised estimator appeals to the
\emph{bias-variance tradeoff} seeks to directly minimise the
cross-validated prediction error (as a function of \(L_2\) loss), that
is decomposable to the sum of variance (imprecision) and bias-squared
(inaccuracy) for any estimator (Hastie et al., 2009). It follows that,
we relaxed the requirement of zero bias via introducing a small bias
(sacrificed some accuracy) for a substantially larger drop in variance
(massively improved precision) to achieve better predictive performance.

Despite prior anticipation of the bias being nonzero, it is of interest
to test for its statistical and practical significance and see if it is
acceptably low. For heart-rate-derived breath rate:
\(\mathbf{\hat{r}}\), as an estimator for breath rate based on chest
movements: \(\mathbf{r}\), we can draw a hypothesis test for
\(\mathbf{r} = \beta\mathbf{\hat{r}}\), and due to the linear nature in
projecting the estimator (see Algorithm 4), we have the null and
alternative hypotheses:

\begin{align*}
  &H_0: \text{The estimator } \mathbf{\hat{r}} \text{ is unbiased} \iff \beta = 1 \\
  &H_1: \text{The estimator } \mathbf{\hat{r}} \text{ is biased} \iff \beta \neq 1
\end{align*}

Therefore, under \(H_0:\)

\begin{align*}
  \frac{1}{\sigma^2}(1 - \hat{\beta})^\top\mathbf{\hat{r}}^\top\mathbf{\hat{r}}(1 - \hat{\beta}) &= \sigma^{-2}\mathbf{\hat{r}}^\top\mathbf{\hat{r}}(1 - \hat{\beta})^2 \\
  &\sim \chi_1^2 \\
  \text{where } \hat{\beta} &= (\mathbf{\hat{r}}^\top\mathbf{\hat{r}})^{-1}\mathbf{\hat{r}}^\top\mathbf{r}
\end{align*}

Which gives the Wald's statistic (Wald, 1943):

\begin{align*}
  W &= \hat{\sigma}^{-2}\mathbf{\hat{r}}^\top\mathbf{\hat{r}}(1 - \hat{\beta})^2 \\
  &= (\dim(\mathbf{r}) - 1) ||(\mathbf{1} - \mathbf{\hat{r}}(\mathbf{\hat{r}}^\top\mathbf{\hat{r}})^{-1}\mathbf{\hat{r}}^\top)\mathbf{r}||^{-2}\mathbf{\hat{r}}^\top\mathbf{\hat{r}}(1 - (\mathbf{\hat{r}}^\top\mathbf{\hat{r}})^{-1}\mathbf{\hat{r}}^\top\mathbf{r})^2 \\
  &= (\dim(\mathbf{r}) - 1) ||(\mathbf{1} - \mathbf{\hat{r}}(\mathbf{\hat{r}}^\top\mathbf{\hat{r}})^{-1}\mathbf{\hat{r}}^\top)\mathbf{r}||^{-2}(\mathbf{\hat{r}}^\top\mathbf{\hat{r}} - \mathbf{\hat{r}}^\top\mathbf{r})^2
\end{align*}

Applied to the results of our final model, we have the Wald's
\(p\)-value \(\mathbb{P}(\chi_1^2 > W) = 2.983174 \times 10^{-13}\),
which provides a very strong evidence for the estimator
\(\mathbf{\hat{r}}\) being biased. However, a further assessment on the
95\% asymptotic confidence interval of \(\beta\), (0.9521173,
0.9724053), indicates the bias is acceptable.

\newpage

\hypertarget{conclusion-and-further-research}{%
\section{Conclusion and further
research}\label{conclusion-and-further-research}}

\hypertarget{model-evaluation}{%
\subsection{Model evaluation}\label{model-evaluation}}

Despite we have justified the \emph{goodness of fit} for the model, that
the heart rate is useful for predicting respiratory rate, model
diagnostics based on the training results might give an optimistic
estimate for the prediction error. Hence, to neutrally assess the
predictive performance of the model, its predictive power shall be
tested in a separate \emph{test} data set (c01-03), via \emph{root mean
squared error of prediction} (RMSEP).

When estimated optimal value of the regularisation parameter
\(\lambda = 1.571851 \times 10^{-6}\) is used in the model and applied
to the \emph{test} data set, the RMSEP is approximately 5.49 breaths per
minute (or 33.95\% off the observed respiratory rate). Unfortunately but
not surprisingly, it is difficult to, using cardio-activities alone,
both \emph{precisely} and \emph{accurately} predict the respiratory rate
using \emph{classical} statistical methods. Nonetheless, the findings in
this project delivered compelling evidence for the feasibility of
respiratory rate prediction using heart rate as one of the predictors,
and a direction for implementation.

A lack of information from the \emph{training} data set is a major
reason of the under-satisfactory predictive performance of the model.
Despite the records are eight hours long at 100Hz each with
approximately 3 million data points, the sufficiency in sample size is
only useful for building a model robust to abnormal signal. However,
merely five individuals are unlikely able to give an adequate
generalisation for the population. As such, preferably, the model should
be trained using random sample of at least hundreds (even thousands) of
individuals, from target populations (children under 5), as a guidance
for further researches in this topic.

\hypertarget{extending-the-model}{%
\subsection{Extending the model}\label{extending-the-model}}

Another major factor responsible for the low predictive power is due to
the limitations of the \emph{classical} statistical regime. In the
following sections, two possible extensions to the model are briefly
discussed.

\hypertarget{bayesian-approach-and-random-effects-models}{%
\subsubsection{Bayesian approach and random effects
models}\label{bayesian-approach-and-random-effects-models}}

The model outlined in this report naively assumed \emph{fixed effects},
such that there exists a single true transformation to map the
predictors to fitted values. Contextually, we were claiming that, the
relationship of heart rate and respiratory rate is the same for all
individuals, and it is unaffected by other factors.

A Bayesian extension to our model into a \emph{random effects model} is
able to free us from the assumption of \emph{fixed effects}, which helps
us model for additional physiological factors such as weight. It is
worth noting that Bayesian statistical learning involves posterior
computation, that often relies on stochastic simulation such as Markov
chain Monte Carlo, which is much more time-consuming to train than the
current model.

\hypertarget{deep-learning-and-double-descent}{%
\subsubsection{Deep learning and double
descent}\label{deep-learning-and-double-descent}}

Deep learning with \emph{artificial neural networks} gives another
direction for further researches. The advantage of deep learning over
\emph{classical} statistics is that it pushes the model beyond
\emph{bias-variance tradeoff}. While for \emph{classical} methods the
effective number of parameters cannot exceed the training sample size,
the model complexity of neural network is not restricted by its training
sample. Notwithstanding for both deep learning and \emph{classical}
methods, the predictive power suffers whenever the effective parameter
size grows toward the training sample size, the over-parameterisation in
neural networks allows for a second descent in the loss curve (also
referred to as risk curve), in a phenomenon called the \emph{double
descent} (Belkin et al., 2019). Such effect of \emph{double descent} has
only recently been shown by research in \emph{convolutional neural
network}, \emph{residual neural network} and \emph{transformers}
(Nakkiran et al., 2019).

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{figure/ddd} 

}

\caption{Visualisation in Belkin et al. (2019): (a) Bias-variance tradeoff in classical methods. (b) Double descent loss curve from modern interpolating regime, potentially giving better predictions.}\label{fig:ddd}
\end{figure}

\hypertarget{open-and-reproducible-research}{%
\subsection{Open and reproducible
research}\label{open-and-reproducible-research}}

The source files and data for reproducing the report, the output of the
project and history of all edits are available at the GitHub repository
\href{https://github.com/szmsu2011/comp90072}{szmsu2011/comp90072}.

\newpage

\hypertarget{appendix-model-training-workflow-code-and-output}{%
\section{Appendix: model training workflow, code and
output}\label{appendix-model-training-workflow-code-and-output}}

\hypertarget{source-code}{%
\subsection{Source code}\label{source-code}}

The source codes for the functions used in the workflow are in the
\texttt{.R} files at
\href{https://github.com/szmsu2011/comp90072/blob/main/R}{/R}.

\hypertarget{data-wrangling-and-signal-processing}{%
\subsection{Data wrangling and signal
processing}\label{data-wrangling-and-signal-processing}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{training\_set }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"a01"}\NormalTok{, }\StringTok{"a02"}\NormalTok{, }\StringTok{"a03"}\NormalTok{, }\StringTok{"a04"}\NormalTok{, }\StringTok{"b01"}\NormalTok{)}
\NormalTok{test\_set }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"c01"}\NormalTok{, }\StringTok{"c02"}\NormalTok{, }\StringTok{"c03"}\NormalTok{)}
\NormalTok{hr }\OtherTok{\textless{}{-}} \FunctionTok{fuse\_data}\NormalTok{(}\FunctionTok{map}\NormalTok{(}
  \FunctionTok{sprintf}\NormalTok{(}\StringTok{"../data{-}bin/\%s.dat"}\NormalTok{, training\_set),}
  \ControlFlowTok{function}\NormalTok{(ecg\_file) \{}
\NormalTok{    ecg\_file }\SpecialCharTok{|\textgreater{}}
      \FunctionTok{read\_ecg}\NormalTok{() }\SpecialCharTok{|\textgreater{}}
      \FunctionTok{find\_r\_peaks}\NormalTok{() }\SpecialCharTok{|\textgreater{}}
      \FunctionTok{frequency}\NormalTok{() }\SpecialCharTok{|\textgreater{}}
      \FunctionTok{down\_sample}\NormalTok{()}
\NormalTok{  \}}
\NormalTok{))}
\NormalTok{resp }\OtherTok{\textless{}{-}} \FunctionTok{fuse\_data}\NormalTok{(}\FunctionTok{map}\NormalTok{(}
  \FunctionTok{sprintf}\NormalTok{(}\StringTok{"../data{-}bin/\%sr.dat"}\NormalTok{, training\_set),}
  \ControlFlowTok{function}\NormalTok{(resp\_file) }\FunctionTok{down\_sample}\NormalTok{(}\FunctionTok{read\_resp}\NormalTok{(resp\_file))}
\NormalTok{))}
\NormalTok{hr\_test }\OtherTok{\textless{}{-}} \FunctionTok{fuse\_data}\NormalTok{(}\FunctionTok{map}\NormalTok{(}
  \FunctionTok{sprintf}\NormalTok{(}\StringTok{"../data{-}bin/\%s.dat"}\NormalTok{, test\_set),}
  \ControlFlowTok{function}\NormalTok{(ecg\_file) \{}
\NormalTok{    ecg\_file }\SpecialCharTok{|\textgreater{}}
      \FunctionTok{read\_ecg}\NormalTok{() }\SpecialCharTok{|\textgreater{}}
      \FunctionTok{find\_r\_peaks}\NormalTok{() }\SpecialCharTok{|\textgreater{}}
      \FunctionTok{frequency}\NormalTok{() }\SpecialCharTok{|\textgreater{}}
      \FunctionTok{down\_sample}\NormalTok{()}
\NormalTok{  \}}
\NormalTok{))}
\NormalTok{resp\_test }\OtherTok{\textless{}{-}} \FunctionTok{fuse\_data}\NormalTok{(}\FunctionTok{map}\NormalTok{(}
  \FunctionTok{sprintf}\NormalTok{(}\StringTok{"../data{-}bin/\%sr.dat"}\NormalTok{, test\_set),}
  \ControlFlowTok{function}\NormalTok{(resp\_file) }\FunctionTok{down\_sample}\NormalTok{(}\FunctionTok{read\_resp}\NormalTok{(resp\_file))}
\NormalTok{))}
\FunctionTok{write\_rds}\NormalTok{(hr, }\StringTok{"../R/hr.rds"}\NormalTok{)}
\FunctionTok{write\_rds}\NormalTok{(resp, }\StringTok{"../R/resp.rds"}\NormalTok{)}
\FunctionTok{write\_rds}\NormalTok{(hr\_test, }\StringTok{"../R/hr{-}test.rds"}\NormalTok{)}
\FunctionTok{write\_rds}\NormalTok{(resp\_test, }\StringTok{"../R/resp{-}test.rds"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{model-training}{%
\subsection{Model training}\label{model-training}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{hr }\OtherTok{\textless{}{-}} \FunctionTok{read\_rds}\NormalTok{(}\StringTok{"../R/hr.rds"}\NormalTok{)}
\NormalTok{resp }\OtherTok{\textless{}{-}} \FunctionTok{read\_rds}\NormalTok{(}\StringTok{"../R/resp.rds"}\NormalTok{)}
\NormalTok{resp\_df }\OtherTok{\textless{}{-}} \FunctionTok{resp\_dataset}\NormalTok{(hr, resp)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{attributes}\NormalTok{(resp\_df)}\SpecialCharTok{$}\NormalTok{opt\_lambda}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
#>   opt_lambda 
#> 1.571851e-06
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{resp\_df}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
#> # A tibble: 2,526 x 2
#>    breath_chest breath_ecg
#>  *        <dbl>      <dbl>
#>  1         19.5       15  
#>  2         22.5       16  
#>  3         23.5       17.5
#>  4         20.5       18  
#>  5         20.5       18  
#>  6         23         15  
#>  7         16         18  
#>  8         20         21.5
#>  9         20         17.5
#> 10         18         16.5
#> # i 2,516 more rows
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(resp\_df)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
#>   breath_chest     breath_ecg   
#>  Min.   : 5.50   Min.   :11.50  
#>  1st Qu.:15.00   1st Qu.:17.50  
#>  Median :18.50   Median :19.00  
#>  Mean   :18.46   Mean   :18.96  
#>  3rd Qu.:21.38   3rd Qu.:20.50  
#>  Max.   :29.00   Max.   :26.50
\end{verbatim}

\hypertarget{model-diagnostics-1}{%
\subsection{Model diagnostics}\label{model-diagnostics-1}}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{c}\NormalTok{(}\StringTok{"R{-}F cor"} \OtherTok{=} \FunctionTok{with}\NormalTok{(resp\_df, }\FunctionTok{cor}\NormalTok{(breath\_chest }\SpecialCharTok{{-}}\NormalTok{ breath\_ecg, breath\_ecg)))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
#>    R-F cor 
#> -0.3976376
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{test }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(breath\_chest }\SpecialCharTok{\textasciitilde{}} \DecValTok{0} \SpecialCharTok{+}\NormalTok{ breath\_ecg, resp\_df)}
\FunctionTok{c}\NormalTok{(}\StringTok{"p{-}value"} \OtherTok{=} \FunctionTok{unname}\NormalTok{(}\FunctionTok{pchisq}\NormalTok{(}
  \FunctionTok{sum}\NormalTok{(resp\_df}\SpecialCharTok{$}\NormalTok{breath\_ecg}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ (}\FunctionTok{coef}\NormalTok{(test) }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{)}\SpecialCharTok{\^{}}\DecValTok{2} \SpecialCharTok{*}
\NormalTok{    (}\FunctionTok{nrow}\NormalTok{(resp\_df) }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{) }\SpecialCharTok{/} \FunctionTok{sum}\NormalTok{(}\FunctionTok{residuals}\NormalTok{(test)}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{), }\DecValTok{1}\NormalTok{,}
  \AttributeTok{lower.tail =} \ConstantTok{FALSE}
\NormalTok{)))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
#>      p-value 
#> 2.983174e-13
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{confint}\NormalTok{(test)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
#>                2.5 %    97.5 %
#> breath_ecg 0.9521173 0.9724053
\end{verbatim}

\hypertarget{model-evaluation-1}{%
\subsection{Model evaluation}\label{model-evaluation-1}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{hr\_test }\OtherTok{\textless{}{-}} \FunctionTok{read\_rds}\NormalTok{(}\StringTok{"../R/hr{-}test.rds"}\NormalTok{)}
\NormalTok{resp\_test }\OtherTok{\textless{}{-}} \FunctionTok{read\_rds}\NormalTok{(}\StringTok{"../R/resp{-}test.rds"}\NormalTok{)}
\NormalTok{resp\_dt }\OtherTok{\textless{}{-}} \FunctionTok{resp\_dataset}\NormalTok{(hr\_test, resp\_test, }\FloatTok{1.571851e{-}06}\NormalTok{)}
\FunctionTok{c}\NormalTok{(}\AttributeTok{RMSEP =} \FunctionTok{with}\NormalTok{(resp\_dt, }\FunctionTok{sqrt}\NormalTok{(}\FunctionTok{mean}\NormalTok{((breath\_chest }\SpecialCharTok{{-}}\NormalTok{ breath\_ecg)}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{))))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
#>    RMSEP 
#> 5.489861
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{c}\NormalTok{(}\StringTok{"RMSEP percentage"} \OtherTok{=} \FunctionTok{with}\NormalTok{(resp\_dt, }\FunctionTok{sqrt}\NormalTok{(}\FunctionTok{mean}\NormalTok{((}\DecValTok{1} \SpecialCharTok{{-}}
\NormalTok{  breath\_ecg }\SpecialCharTok{/}\NormalTok{ breath\_chest)}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{))) }\SpecialCharTok{*} \DecValTok{100}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
#> RMSEP percentage 
#>         33.94976
\end{verbatim}

\newpage

\hypertarget{references}{%
\section*{References}\label{references}}
\addcontentsline{toc}{section}{References}

\hypertarget{refs}{}
\begin{CSLReferences}{1}{1}
\leavevmode\vadjust pre{\hypertarget{ref-Becker1988}{}}%
Becker, R. A., Chambers, J. M., \& Wilks, A. R. (1988). \emph{The new s
language}. Wadsworth \& Brooks/Cole.

\leavevmode\vadjust pre{\hypertarget{ref-Belkin2019}{}}%
Belkin, M., Hsu, D., Ma, S., \& Mandal, S. (2019). Reconciling modern
machine-learning practice and the classical bias{\textendash}variance
trade-off. \emph{Proceedings of the National Academy of Sciences},
\emph{116}(32), 15849--15854.
\url{https://doi.org/10.1073/pnas.1903070116}

\leavevmode\vadjust pre{\hypertarget{ref-Chambers1992}{}}%
Chambers, J. M., \& Hastie, T. (1992). \emph{Statistical models in s}.
{Wadsworth \& Brooks/Cole}.

\leavevmode\vadjust pre{\hypertarget{ref-Cooley1965}{}}%
Cooley, J. W., \& Tukey, J. W. (1965). An algorithm for the machine
calculation of complex fourier series. \emph{Mathematics of
Computation}, \emph{19}(90), 297--301.
\url{https://doi.org/10.2307/2003354}

\leavevmode\vadjust pre{\hypertarget{ref-Giannakopoulos2014}{}}%
Giannakopoulos, T., \& Pikrakis, A. (2014). \emph{Introduction to audio
analysis: A MATLAB approach}. Academic Press.
\url{https://doi.org/10.1016/C2012-0-03524-7}

\leavevmode\vadjust pre{\hypertarget{ref-Goldberger2000}{}}%
Goldberger, A. L., Amaral, L. A., Glass, L., Hausdorff, J. M., Ivanov,
P. C., Mark, R. G., Mietus, J. E., Moody, G. B., Peng, C.-K., \&
Stanley, H. E. (2000). Physiobank, physiotoolkit, and physionet.
\emph{Circulation}, \emph{101}(23), e215--e220.

\leavevmode\vadjust pre{\hypertarget{ref-Goldberger2017}{}}%
Goldberger, A. L., Goldberger, Z. D., \& Shvilkin, A. (2017).
\emph{Goldberger's clinical electrocardiography: A simplified approach}
(9th ed.). Elsevier. \url{https://doi.org/10.1016/C2014-0-03319-9}

\leavevmode\vadjust pre{\hypertarget{ref-Green1994}{}}%
Green, P. J., \& Silverman, B. W. (1994). \emph{Nonparametric regression
and generalized linear models: A roughness penalty approach}. {Chapman
and Hall}.

\leavevmode\vadjust pre{\hypertarget{ref-Hastie1990}{}}%
Hastie, T., \& Tibshirani, R. (1990). \emph{Generalized additive
models}. {Chapman and Hall}.

\leavevmode\vadjust pre{\hypertarget{ref-Hastie2009}{}}%
Hastie, T., Tibshirani, R., \& Friedman, J. H. (2009). \emph{The
elements of statistical learning: Data mining, inference, and
prediction} (2nd ed., pp. 37--38). Springer New York.
\url{https://hastie.su.domains/Papers/ESLII.pdf}

\leavevmode\vadjust pre{\hypertarget{ref-Larsen2010}{}}%
Larsen, P. D., Tzeng, Y. C., Sin, P. Y. W., \& Galletly, D. C. (2010).
Respiratory sinus arrhythmia in conscious humans during spontaneous
respiration. \emph{Respiratory Physiology \& Neurobiology},
\emph{174}(1--2), 111--118.
\url{https://doi.org/10.1016/j.resp.2010.04.021}

\leavevmode\vadjust pre{\hypertarget{ref-Nakkiran2019}{}}%
Nakkiran, P., Kaplun, G., Bansal, Y., Yang, T., Barak, B., \& Sutskever,
I. (2019). \emph{Deep double descent: Where bigger models and more data
hurt}. \url{https://arxiv.org/abs/1912.02292}

\leavevmode\vadjust pre{\hypertarget{ref-Nyquist1928}{}}%
Nyquist, H. (1928). Certain topics in telegraph transmission theory.
\emph{Transactions of the American Institute of Electrical Engineers},
\emph{47}(2), 617--644.
\url{https://doi.org/10.1109/T-AIEE.1928.5055024}

\leavevmode\vadjust pre{\hypertarget{ref-Penzel2000}{}}%
Penzel, T., Moody, G. B., Mark, R. G., Goldberger, A. L., \& Peter, J.
H. (2000). The apnea-ecg database. \emph{Computers in Cardiology 2000},
255--258.

\leavevmode\vadjust pre{\hypertarget{ref-R}{}}%
R Core Team. (2023). \emph{R: A language and environment for statistical
computing}. R Foundation for Statistical Computing.
\url{https://www.R-project.org/}

\leavevmode\vadjust pre{\hypertarget{ref-Shamoon2004}{}}%
Shamo'on, H., Hawamdah, A., Haddadin, R., \& Jmeian, S. (2004).
Detection of pneumonia among children under six years by clinical
evaluation. \emph{East Mediterr Health J}, \emph{10}(4-5), 482--487.

\leavevmode\vadjust pre{\hypertarget{ref-Single1979}{}}%
Singleton, R. C. (1979). Mixed radix fast fourier transforms. In IEEE
Digital Signal Processing Committee (Ed.), \emph{Programs for digital
signal processing}. IEEE Press.

\leavevmode\vadjust pre{\hypertarget{ref-Wald1943}{}}%
Wald, A. (1943). Tests of statistical hypotheses concerning several
parameters when the number of observations is large. \emph{Transactions
of the American Mathematical Society}, \emph{54}, 426--482.
\url{https://doi.org/10.1090/S0002-9947-1943-0012401-3}

\leavevmode\vadjust pre{\hypertarget{ref-WHO2022}{}}%
World Health Organisation. (2022). \emph{Pneumonia in children}.
\url{https://www.who.int/news-room/fact-sheets/detail/pneumonia}

\end{CSLReferences}

\end{document}
